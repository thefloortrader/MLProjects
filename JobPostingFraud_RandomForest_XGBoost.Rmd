```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pROC)
library(caret)
library(tidyverse)
library(lubridate)
library(janitor)
library(skimr)
library(lubridate)
library(RSocrata)
library(tidyquant)
library(tidymodels)
library(ranger)
library(topicmodels)
library(readr)
library(tidyverse)
library(lubridate)
library(dplyr)
library(tidytext)
library(rtweet)
library(readxl)
library(janitor)
library(devtools)
library(Rcpp)
library(vip)
library(ggplot2)
library(ggthemes)
library(corrplot)
library(corrr)
library(MASS)
library(VIF)
library(vip)
library(fastDummies)
library(kableExtra)
library(GGally)
library(kableExtra)
library(parallel)
library(doParallel)
library(fastshap)
library(rpart.plot)
library(ggpubr)
library(imputeTS)
library(xgboost)
library(glmnet) 
library(rpart.plot) 
library(reshape2)
library(embed)
library(textrecipes)
library(stopwords)
```

## Important Vars: presence of logo, salary range, having questions

```{r}
job_training <- read_csv("job_training.csv") %>%
  clean_names() %>%
  mutate(fraudulent = as_factor(fraudulent))

holdout <- read_csv("job_holdout.csv") %>%
  clean_names()
```

```{r}
job_training %>%
  skim_without_charts()

holdout %>%
    skim_without_charts()

#factors with unusable completion rate (in increasingly useful order): salary_range, department
#factors with above 50% but below 75% completion rate (in increasingly useful order): required_education, benefits, required_experience, job_function, industry
#all character values bar title and location are in 0.8-0.9 range
```

## Frequency Encoding (description)
```{r}
descrip_freq <- job_training %>%
  group_by(description) %>%
  summarise(descrip_freq = n())

job_training <- job_training %>%
  left_join(descrip_freq) %>%
  dplyr::select(-description)

head(descrip_freq)

holdout <- holdout %>%
  left_join(descrip_freq) %>%
  dplyr::select(-description)
```

## Target Encoding (title)
```{r}
title_targ_enc <- job_training %>%
  group_by (title, fraudulent) %>%
  summarise(n = n()) %>%
  pivot_wider(names_from=fraudulent, values_from=n, values_fill = 0) %>%
  mutate(title_targ_enc = `1`/(`0`+`1`)) %>%
  dplyr::select(title, title_targ_enc)

job_training <- job_training %>%
  left_join(title_targ_enc) %>%
  dplyr::select(-title)

head(title_targ_enc)

holdout <- holdout %>%
  left_join(title_targ_enc) %>%
  dplyr::select(-title)

head(title_targ_enc)
```

```{r}
#Target Exploration

job_training %>%
  group_by(fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) -> target_fraud

TC_plotf  <- ggtexttable(target_fraud, rows = NULL, 
                        theme = ttheme("mOrange"))

target_fraud %>%
  ggplot(aes(x = fraudulent, y = n)) +
  geom_col() + 
  labs("Fraudulent Target Counts") -> p1f

target_fraud %>%
  ggplot(aes(x = fraudulent, y = pct)) +
  geom_col() + 
  labs(title = "Fraudulent Target") -> p2f

ggarrange(p2f, TC_plotf, 
          ncol = 1, nrow = 2,
          heights = c(1, 0.3)) 

job_training <- na_mean(job_training)

fraud_cormat <- job_training %>%
  select_if(is.numeric) %>%
  na.omit() %>%
  cor() %>%
  round(digits = 4) %>%
  melt()

fraud_cormat %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(mid = "#FBFEF9",low = "#A63446",high = "#0C6291") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_text(aes(label = round(value, 3)), color = "blue") +
  labs(title = "Correlation Matrix")
```

```{r}
#Exploratory Analysis for Numerics (all Binary)
job_training %>%
  mutate(fraudulent = as.character(fraudulent)) %>%
  ggplot(aes(telecommuting, fill = fraudulent))+
  geom_bar(bins = 2, position = "fill")+
  labs(title = "does telecommuting = higher fraudulent occurence?") +
  ylab("pct")+
  xlab("telecommuting")

job_training %>%
  group_by(telecommuting)%>%
  summarize(n = n()) %>%
  mutate(pct = n/sum(n))

job_training %>%
  mutate(fraudulent = as.character(fraudulent)) %>%
  ggplot(aes(has_company_logo, fill = fraudulent))+
  geom_bar(bins = 2, position = "fill")+
  labs(title = "does has_company_logo = higher fraudulent occurence?") +
  ylab("pct")+
  xlab("has_company_logo")

job_training %>%
  group_by(has_company_logo)%>%
  summarize(n = n()) %>%
  mutate(pct = n/sum(n))

job_training %>%
  mutate(fraudulent = as.character(fraudulent)) %>%
  ggplot(aes(has_questions, fill = fraudulent))+
  geom_bar(bins=2, position = "fill")+
  labs(title = "does has_questions = higher fraudulent occurence?") +
  ylab("pct")+
  xlab("has_questions")

job_training %>%
  group_by(has_questions)%>%
  summarize(n = n()) %>%
  mutate(pct = n/sum(n))
```
```{r}
#Exploratory Analysis Character Variables
  #High Cardinality varaibles such as company_profile, description, requirements, and benefits were not graphed as were too varied.

#Agency Sales Managers $150-$175,000/yr, Call Center Representative I, Cruise Staff Wanted *URGENT*,Data Entry Admin/Clerical Positions - Work From Home, Home Based Payroll Typist/Data Entry Clerks Positions Available, Home Based Payroll Data Entry Clerk Position - Earn $100-$200 Daily,Network Marketing, Payroll Clerk	,Payroll Data Coordinator Positions - Earn $100-$200 Daily, data entry

job_training %>%
  group_by(location, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         location_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(location_pct_fraudulent)) -> location_fraud_rate

location_fraud_rate

job_training %>%
  group_by(department, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         department_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(department_pct_fraudulent)) -> department_fraud_rate

department_fraud_rate

#clerical, oil

job_training %>%
  group_by(employment_type, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         employment_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(employment_pct_fraudulent)) -> employment_type_fraud_rate

employment_type_fraud_rate
 
job_training %>%
  group_by(employment_type) %>%
  summarize(n = n()) %>%
  mutate(pct = n/sum(n))
 
job_training %>%
  group_by(employment_type, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = employment_type, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Employment Type")

job_training %>%
  group_by(employment_type, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(employment_type, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Employment Type")

job_training %>%
  group_by(required_experience, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         experience_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(experience_pct_fraudulent)) -> r_experience_fraud_rate

r_experience_fraud_rate
 
job_training %>%
  group_by(required_experience, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = required_experience, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Required Experience")

job_training %>%
  group_by(required_experience, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(required_experience, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Required Experience")

job_training %>%
  group_by(required_education, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill=0) %>%
  mutate(n = `0` + `1`,
         education_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(education_pct_fraudulent)) -> r_education_fraud_rate

r_education_fraud_rate
 
job_training %>%
  group_by(required_education, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = required_education, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Required Education")

job_training %>%
  group_by(required_education, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(required_education, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Required Education")

job_training %>%
  group_by(industry, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         industry_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(industry_pct_fraudulent)) -> industry_fraud_rate

industry_fraud_rate
 
job_training %>%
  group_by(industry, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = industry, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Industry")

job_training %>%
  group_by(industry, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(industry, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Industry")

#lowly oil and energy, accounting, Leisure, Travel & Tourism
#low but higer n Hospital & Health Care, Telecommunications, Human Resources

job_training %>%
  group_by(job_function, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         job_function_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(job_function_pct_fraudulent)) -> job_function_fraud_rate

job_function_fraud_rate
 
job_training %>%
  group_by(job_function, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = job_function, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Job Function")

job_training %>%
  group_by(job_function, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(job_function, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Job Function")

job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         salary_pct_fraudulent = round(`1`/n,3)) %>%
  arrange(desc(salary_pct_fraudulent)) -> salary_range_fraud_rate

salary_range_fraud_rate
 
job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = salary_range, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Salary Range")

job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(salary_range, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Salary Range")

job_training %>%
  group_by(company_profile, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         company_profile_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(company_profile_pct_fraudulent)) -> company_profile_fraud_rate

company_profile_fraud_rate

job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = salary_range, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Salary Range")

job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(salary_range, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Salary Range")

job_training %>%
  group_by(descrip_freq, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         description_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(description_pct_fraudulent)) -> description_fraud_rate

description_fraud_rate

job_training %>%
  group_by(descrip_freq, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = descrip_freq, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Description (frequency encoded)")

job_training %>%
  group_by(salary_range, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(salary_range, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Description (frequency encoded)")

job_training %>%
  group_by(title_targ_enc, fraudulent) %>%
  summarise(n = n())  %>%
  pivot_wider(names_from = fraudulent, values_from = n, values_fill = 0) %>%
  mutate(n = `0` + `1`,
         description_pct_fraudulent = round(`1`/n, 3)) %>%
  arrange(desc(description_pct_fraudulent)) -> title_fraud_rate

title_fraud_rate

job_training %>%
  group_by(title_targ_enc, fraudulent) %>%
  summarise(n = n()) %>%
  ggplot(aes(y = title_targ_enc, x = n, fill = fraudulent)) + 
  geom_col() +
  labs(title = "Fraud by Title (target encoded)")

job_training %>%
  group_by(title_targ_enc, fraudulent) %>%
  summarise(n = n()) %>%
  mutate(pct = n/sum(n)) %>%
  ggplot(aes(y = reorder(title_targ_enc, pct), x = n, fill = fraudulent)) + 
  geom_col(position = "fill") +
  labs(title = "Fraud by Title (target encoded)")

```

## Factors 

```{r}
#High Cardinality: job_id, title, location, department, salary_range, company_profile, description, requirements, benefits, industry,

job_training %>%
  mutate_if(is.character, as.factor)

holdout %>%
  mutate_if(is.character, as.factor)
```

```{r}
set.seed(123)

train_test_spit <- initial_split(job_training, prop = 0.7, strata = fraudulent)

train <- training(train_test_spit)
test  <- testing(train_test_spit)
train_cv_folds <- vfold_cv(train, v = 5)

sprintf("Train PCT : %1.1f%%", nrow(train)/ nrow(job_training) * 100)
sprintf("Test PCT : %1.1f%%", nrow(test)/ nrow(job_training) * 100)
sprintf("Kfold Count: %d", nrow(train_cv_folds))
```

```{r, message=FALSE, warning=FALSE}
recipe1 <- recipe(fraudulent ~ ., data = train) %>%
  step_rm(job_id) %>%
  step_meanimpute(all_numeric()) %>%
  step_unknown(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function) %>%
  step_tokenize(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function) %>%
  step_stopwords(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function) %>%
  step_ngram(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function, num_tokens = 3, min_num_tokens = 1) %>%
  step_tokenfilter(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function, max_tokens = 10) %>%
  step_tfidf(location, department, salary_range, company_profile, requirements, benefits, employment_type, required_experience, required_education, industry, job_function)
  
juice(recipe1 %>% prep())

recipe1
```


```{r, message=FALSE, warning=FALSE}
## -- RANDOM FOREST -- 

rf_model1 <- rand_forest(trees = 100, min_n = 10) %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("classification") 

rf_workflow1 <- workflow() %>%
  add_recipe(recipe1) %>%
  add_model(rf_model1) %>%
  fit(data = train)

rf_tune_grid1 <- grid_random(trees(), 
                            min_n(),
                            size = 5)

rf_tuning_results1 <- rf_workflow1 %>% 
  tune_grid(
    resamples = train_cv_folds,
    grid = rf_tune_grid1,
    metrics = metric_set(roc_auc),
    control = control_resamples(save_pred = TRUE)
    )

rf_tuning_results1 %>%
  unnest(.notes) ## use this to debug your model

rf_tuning_results1 %>%
  collect_metrics()
```


```{r, message=FALSE, warning=FALSE}
## -- XG BOOST -- 
# Parallel
 all_cores <- detectCores(logical = TRUE)
 sprintf("# of Logical Cores: %d", all_cores)
 cl <- makeCluster(all_cores)
 registerDoParallel(cl)

 set.seed(1000)

xgb_model1 <- boost_tree(trees = 100, min_n = 10) %>%
  set_engine("xgboost") %>%
  set_mode("classification") 

xgb_workflow1 <- workflow() %>%
  add_recipe(recipe1) %>%
  add_model(xgb_model1) %>%
  fit(data = train)

xgb_tune_grid1 <- grid_regular(trees(c(10,20)),
                          learn_rate(c(-1,-2)),
                          levels = 2)

print(xgb_tune_grid1)

xgb_tuning_results1 <- xgb_workflow1 %>% 
  tune_grid(
    resamples = train_cv_folds,
    grid = xgb_tune_grid1,
    metrics = metric_set(roc_auc),
    control = control_resamples(save_pred = TRUE)
    )

xgb_tuning_results1 %>%
  unnest(.notes) ## use this to debug your model

xgb_tuning_results1 %>%
  collect_metrics() %>%
  mutate_if(is.numeric, round, 3)

xgb_tuning_results1 %>%
  show_best("roc_auc") %>%
  print()

xgb_best <- xgb_tuning_results1 %>%
  select_best("roc_auc") 

print(xgb_best)

xgb_final_wf <- xgb_workflow1 %>% 
  finalize_workflow(xgb_best)

print(xgb_final_wf)

xgb_final_fit  <- xgb_final_wf %>%
  fit(data = train) 
```

## Training Predictions

```{r, message=FALSE, warning=FALSE}
predict(rf_workflow1, train) %>%
  bind_cols(predict(rf_workflow1, train, type = "prob"))%>%
  bind_cols(train) -> train_scoredrf1

predict(rf_workflow1, test) %>%
  bind_cols(predict(rf_workflow1, test, type = "prob")) %>%
  bind_cols(test) -> test_scoredrf1

predict(xgb_workflow1, train) %>%
  bind_cols(predict(xgb_workflow1, train, type = "prob"))%>%
  bind_cols(train) -> train_scoredxgb1

predict(xgb_workflow1, test) %>%
  bind_cols(predict(xgb_workflow1, test, type = "prob")) %>%
  bind_cols(test) -> test_scoredxgb1
```
  
```{r}
options(yardstick.event_first=FALSE)

train_scoredrf1 %>%
  metrics(fraudulent, `.pred_1`, estimate = .pred_class) %>%
  mutate(part = "training") %>%
  bind_rows(test_scoredrf1 %>%
              metrics(fraudulent, `.pred_1`, estimate = .pred_class) %>%
              mutate(part = "testing") ) %>%
  filter(.metric %in% c('accuracy', 'roc_auc')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)
  
  # -- variable importance: top 25
rf_workflow1 %>%
  pull_workflow_fit() %>%
  vip(num_features = 25)
  
  # -- confusion matrix 
train_scoredrf1 %>%
  conf_mat(fraudulent, .pred_class) %>%
  autoplot(type = "heatmap")

test_scoredrf1 %>%
  conf_mat(fraudulent, .pred_class) %>%
  autoplot(type = "heatmap")
   
  # -- ROC Charts 
train_scoredrf1 %>%
  mutate(model = "train") %>%
  bind_rows(test_scoredrf1 %>%
              mutate(model = "test")) %>%
  group_by(model) %>%
  roc_curve(fraudulent, `.pred_1`) %>%
  autoplot() 

  # -- operating range -- 
train_scoredrf1  %>%
  roc_curve(fraudulent, `.pred_1`) %>%
  mutate(FPR = round((1 - specificity), 2),
         TPR = round(sensitivity,3),
         score_threshold =  1 - round(.threshold, 3)) %>%
  group_by(FPR) %>%
  summarise(score_threshold = max(score_threshold),
            TPR = max(TPR))%>%
  ungroup() %>%
  mutate(precision = TPR/(TPR + FPR)) %>%
  dplyr::select(FPR, TPR, precision, score_threshold) %>%
  filter(FPR <= 0.1) 
```

  
```{r}
options(yardstick.event_first=FALSE)

train_scoredxgb1 %>%
  metrics(fraudulent, `.pred_1`, estimate = .pred_class) %>%
  mutate(part = "training") %>%
  bind_rows(test_scoredxgb1 %>%
              metrics(fraudulent, `.pred_1`, estimate = .pred_class) %>%
              mutate(part = "testing") ) %>%
  filter(.metric %in% c('accuracy', 'roc_auc')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)
  
  # -- variable importance: top 25
xgb_workflow1 %>%
  pull_workflow_fit() %>%
  vip(num_features = 25)
  
  # -- confusion matrix 
train_scoredxgb1 %>%
  conf_mat(fraudulent, .pred_class) %>%
  autoplot(type = "heatmap")

test_scoredxgb1 %>%
  conf_mat(fraudulent, .pred_class) %>%
  autoplot(type = "heatmap")
   
  options(yardstick.event_first=FALSE)
  # -- ROC Charts 
train_scoredxgb1 %>%
  mutate(model = "train") %>%
  bind_rows(test_scoredxgb1 %>%
              mutate(model = "test")) %>%
  group_by(model) %>%
  roc_curve(fraudulent, `.pred_1`) %>%
  autoplot() 

  # -- operating range -- 
train_scoredxgb1  %>%
  roc_curve(fraudulent, `.pred_1`) %>%
  mutate(FPR = round((1 - specificity), 2),
         TPR = round(sensitivity,3),
         score_threshold =  1 - round(.threshold, 3)) %>%
  group_by(FPR) %>%
  summarise(score_threshold = max(score_threshold),
            TPR = max(TPR))%>%
  ungroup() %>%
  mutate(precision = TPR/(TPR + FPR)) %>%
  dplyr::select(FPR, TPR, precision, score_threshold) %>%
  filter(FPR <= 0.1) 
```

```{r}
options(yardstick.event_first = FALSE)
model_score <- function(job_training, model, model_name){
  scored_df <- predict(model, job_training, type = "prob") %>%
    bind_cols(., predict(model, job_training)) %>%
    bind_cols(job_training) %>%
    mutate(model_name = model_name)
  
  return(scored_df)
}
train_scoredxgb1 <- model_score(train, xgb_final_fit, "xgboost training" )
test_scoredxgb1 <- model_score(test, xgb_final_fit, "xgboost testing" )
```


```{r}
train_scoredrf1 <- model_score(train, rf_workflow1, "xgboost training" )
test_scoredrf1 <- model_score(test, rf_workflow1, "xgboost testing" )
```

## -- XGB Preds -- 

```{r}
options(yardstick.event_first = FALSE)
# -- Metrics: Train and Test -- 
bind_rows(train_scoredxgb1, test_scoredxgb1) %>% 
  group_by(model_name) %>%
  metrics(fraudulent, .pred_1, estimate = .pred_class) %>%
  pivot_wider(id = c(model_name), names_from = .metric, values_from = .estimate) %>%
  mutate(misclassification_rate = 1 - accuracy)

# -- ROC Chart -- 
bind_rows(train_scoredxgb1, test_scoredxgb1) %>% 
  group_by(model_name) %>%
  roc_curve(fraudulent, .pred_1) %>%
  autoplot() +
  geom_vline(xintercept = 0.06, color = "red") +
  labs(title = "XGB ROC chart")

precision(train_scoredxgb1, fraudulent, .pred_class)
recall(test_scoredxgb1, fraudulent, .pred_class)
```

## -- RF Preds -- 

```{r}
options(yardstick.event_first = FALSE)
# -- Metrics: Train and Test -- 

bind_rows(train_scoredrf1, test_scoredrf1) %>% 
  group_by(model_name) %>%
  metrics(fraudulent, .pred_1, estimate = .pred_class) %>%
  pivot_wider(id = c(model_name), names_from = .metric, values_from = .estimate) %>%
  mutate(misclassification_rate = 1 - accuracy)

# -- ROC Chart -- 
bind_rows(train_scoredrf1, test_scoredrf1) %>% 
  group_by(model_name) %>%
  roc_curve(fraudulent, .pred_1) %>%
  autoplot() +
  geom_vline(xintercept = 0.06, color = "red") +
  labs(title = "ROC chart")

precision(train_scoredrf1, fraudulent, .pred_class)
recall(test_scoredrf1, fraudulent, .pred_class)
```

```{r, warning=FALSE, message=FALSE}

# -- Score Training
predict(xgb_workflow1, holdout, type = "prob")%>%
  bind_cols(predict(xgb_workflow1, holdout, type = "class"))%>%
  bind_cols(., holdout) -> holdout_score

holdout <- holdout_score %>%
  dplyr::select(job_id, fraudulent = .pred_1)

write_csv(holdout, "OOT.csv")
```
